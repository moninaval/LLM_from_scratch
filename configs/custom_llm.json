{
  "model_name": "my-llm",

  "data_path": "data/my_corpus.txt",             
  "tokenizer_path": "tokenizers/my-llm-tokenizer",
  "tokenizer_type": "custom",

  "checkpoint_dir": "checkpoints/my-llm",

  "vocab_size": 30000,
  "max_position_embeddings": 1024,

  "hidden_size": 768,
  "num_heads": 12,
  "num_layers": 12,
  "intermediate_size": 3072,
  "vocab_size": 30000,

  "use_rotary": false,
  "norm_type": "layernorm",
  "ffn_type": "gelu",
  "qkv_proj": "split",
  "tie_weights": true,

  "batch_size": 4,
  "lr": 3e-4,
  "epochs": 5,
  "loss": "cross_entropy",
  "device": "cuda",

  "pretokenized": false,
  "save_bin": true
}
